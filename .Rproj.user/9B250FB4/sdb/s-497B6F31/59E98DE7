{
    "contents" : "abandoned = read.csv(\"Data/Abandoned_Data_Seed.csv\",header = T,stringsAsFactors = F)\nreservation = read.csv(\"Data/Reservation_Data_Seed.csv\",header = T,stringsAsFactors = F)\n\nnrow(abandoned)\nreservation[reservation$Test_Control=='test',]\nnrow(reservation[reservation$Test_Control=='test',])\n\n\n#### Getting Duplicates in both Datasets\n#Email only\nmatching_email = match(abandoned$Email,reservation$Email,nomatch = 0)\nmatching_email\nduplicated(matching_email)\nmatching_email[!duplicated(matching_email)] # (76-2) = 74 obs\n\n\n\n#Incoming Phone only\nmatching_incoming = match(abandoned$Incoming_Phone,reservation$Incoming_Phone,nomatch = 0)\n\nduplicated(matching_incoming)\nmatching_incoming[!duplicated(matching_incoming)] # 313 obs\n\n\n#Contact Phone only\nmatching_contact = match(abandoned$Contact_Phone,reservation$Contact_Phone,nomatch = 0)\nduplicated(matching_contact)\nmatching_contact[!duplicated(matching_contact)] # 166 obs\n\n#Eamil | Incoming Phone | Contact \nmatching_eic = ((abandoned$Incoming_Phone %in% reservation$Incoming_Phone) \n                | (abandoned$Contact_Phone %in% reservation$Contact_Phone) \n                | abandoned$Email %in% reservation$Email)& \n                (!duplicated(matching_email) \n                | !duplicated(matching_incoming) \n                | !duplicated(matching_contact)\n                )                                    # To select matching observations in Abandoned DataSet on either email, \n                                                        # incoming or Contact phone and removing any duplicates from either.\nmatching_eic\nsum(matching_eic) \nabandoned_match = abandoned[matching_eic,]\nnrow(abandoned_match) #388 obs in Abandoned matched with obs in Reservation Dataset\n\n### Getting corresponding matching Reservation Dataset\n\nmatching_i_r = match(abandoned$Incoming_Phone, reservation$Incoming_Phone, nomatch = 0)\nmatching_i_r = matching_i_r[!duplicated(matching_i_r)]\nmatching_i_r\n\nmatching_e_r = match(abandoned$Email, reservation$Email, nomatch = 0)\nmatching_e_r = matching_e_r[!duplicated(matching_e_r)]\nmatching_e_r\n\nmatching_c_r = match(abandoned$Contact_Phone, reservation$Contact_Phone, nomatch = 0)\nmatching_c_r = matching_c_r[!duplicated(matching_c_r)]\nmatching_c_r\n\nmatching_eic_r = c(matching_i_r,matching_e_r,matching_c_r)\nmatching_eic_r\n\nmatching_eic_r = matching_eic_r[!duplicated(matching_eic_r)]\nmatching_eic_r\n\nreservation_match <- reservation[matching_eic_r,]\nreservation_match\n\n### Writing Matched datasets\n\nwrite.csv(x = reservation_match, file = \"reservation_match.csv\")\nwrite.csv(x = abandoned_match, file = \"abandoned_match.csv\")\n\n\n\n\n####Cleaning Matched Datasets\n\n\n# Reservation_match Data set cleaning\n# Crosschecking for any errors\nsum(match(reservation_match$Email, abandoned_match$Email, nomatch = 0) | \n  match(reservation_match$Incoming_Phone, abandoned_match$Incoming_Phone, nomatch = 0) |\n  match(reservation_match$Contact_Phone, abandoned_match$Contact_Phone, nomatch = 0))\n\nsum(match(abandoned_match$Email,reservation_match$Email, nomatch = 0) | \n  match( abandoned_match$Incoming_Phone,reservation_match$Incoming_Phone, nomatch = 0) |\n  match( abandoned_match$Contact_Phone, reservation_match$Contact_Phone,nomatch = 0))\n\n# Checking for more than one reservations \nduplicated(reservation_match$Incoming_Phone, incomparables = \"\")\nsum(duplicated(reservation_match$Incoming_Phone,incomparables = \"\")) # 10 obs with >1 reservation from same Incoming Phone\n\nduplicated(reservation_match$Contact_Phone,incomparables = \"\")\nsum(duplicated(reservation_match$Contact_Phone, incomparables = \"\")) # 0 obs with >1 reservation from same Contact Phone\n\nduplicated(reservation_match$Email,incomparables = \"\")\nsum(duplicated(reservation_match$Email, incomparables = \"\")) # 5 obs\n\n# Removing >1 reservation (incoming) obs from reservation_match dataset\nreservation_match_oneres = reservation_match[!duplicated(reservation_match$Incoming_Phone, incomparables = \"\"),]\nnrow(reservation_match_oneres) #same as abandoned_match\n\n# Checking again for duplicate emails \nduplicated(reservation_match_oneres$Email,incomparables = \"\")\nsum(duplicated(reservation_match_oneres$Email, incomparables = \"\"))\n\n# Removing >1 reservation (Email) obs from reservation_match dataset\nreservation_match_oneres <- reservation_match_oneres[!duplicated(reservation_match_oneres$Email, incomparables = \"\"),]\nnrow(reservation_match_oneres) # one less than abandoned_match\n\n# Writing new reservation_match_oneres dataset\nwrite.csv(x = reservation_match_oneres, file = \"reservation_match_oneres.csv\")\n\n\n#Abandoned_match dataset cleaning\n#Finding duplicates\nsum(duplicated(abandoned_match$Incoming_Phone, incomparables = \"\"))\nsum(duplicated(abandoned_match$Contact_Phone, incomparables = \"\")) # 1 dublicate Contact Phone\nsum(duplicated(abandoned_match$Email, incomparables = \"\"))\n\n# Removing duplicates\nabandoned_match[abandoned_match$Contact_Phone==\"(207)-726-7898\",]\nabandoned_match[duplicated(abandoned_match$Contact_Phone, incomparables = \"\"),] # making sure that 8168 is older observation of the two\n\nabandoned_match_nodup <- abandoned_match[!duplicated(abandoned_match$Contact_Phone, incomparables = \"\"),]\nnrow(abandoned_match_nodup) # Same as reservation_match_oneres\n\n# Writing new abandoned_match_nodup data set\nwrite.csv(x = abandoned_match_nodup, file = \"abandoned_match_nodup.csv\")\n\n\n\n#########\n\n# Creating variable for Bought/Not Bought in abandoned_matched_nodup:\n\nabandoned_match_nodup[,13] <- 1  #V13 is variable for Bought(1) and NoBought(0)\n\n# Concatenating Abandoned and Abandoned_match_nodup together in excel\n\nabandoned_match_nodup_all <- read.csv(\"~/Studies/Courses/USF/Statistical Data Mining/MightyHive Project/MightyHive-Project/abandoned_match_nodup_all.csv\",stringsAsFactors = FALSE)\n\n# Removing Duplicates\nsum(duplicated(abandoned_match_nodup_all$Incoming_Phone, incomparables = \"\")) #447\nsum(duplicated(abandoned_match_nodup_all$Contact_Phone, incomparables = \"\")) #516\nsum(duplicated(abandoned_match_nodup_all$Email, incomparables = \"\")) #97\n\nabandoned_match_nodup_all_c <- abandoned_match_nodup_all[!duplicated(abandoned_match_nodup_all$Contact_Phone, incomparables = \"\"),]\nabandoned_match_nodup_all_c <- abandoned_match_nodup_all_c[!duplicated(abandoned_match_nodup_all_c$Incoming_Phone, incomparables = \"\"),]\nabandoned_match_nodup_all_c <- abandoned_match_nodup_all_c[!duplicated(abandoned_match_nodup_all_c$Email, incomparables = \"\"),]\n\nsum(duplicated(abandoned_match_nodup_all_c)) # duplicates removed\n\n#### Creating Dummy Variables\n#Test_Control\nabandoned_match_nodup_all_c$Test_Control[abandoned_match_nodup_all_c$Test_Control==\"control\"] <- 0 \nabandoned_match_nodup_all_c$Test_Control[abandoned_match_nodup_all_c$Test_Control==\"test\"] <- 1 \n\nabandoned_match_nodup_all_c$Test_Control <- as.factor(abandoned_match_nodup_all_c$Test_Control)\n\n#Email\nabandoned_match_nodup_all_c$Email[abandoned_match_nodup_all_c$Email==\"\"] <- 0\nabandoned_match_nodup_all_c$Email[abandoned_match_nodup_all_c$Email!=\"0\"] <- 1\n\nabandoned_match_nodup_all_c$Email <- as.factor(abandoned_match_nodup_all_c$Email)\n\n#Address\nabandoned_match_nodup_all_c$Address[abandoned_match_nodup_all_c$Address==\"\"] <- 0\nabandoned_match_nodup_all_c$Address[abandoned_match_nodup_all_c$Address!=\"0\"] <- 1\n\nabandoned_match_nodup_all_c$Test_Control <- as.factor(abandoned_match_nodup_all_c$Test_Control)\n\n#Contact\nabandoned_match_nodup_all_c$Contact_Phone[abandoned_match_nodup_all_c$Contact_Phone==\"\"] <- 0\nabandoned_match_nodup_all_c$Contact_Phone[abandoned_match_nodup_all_c$Contact_Phone!=\"0\"] <- 1\n\n\n#Interaction Terms\n\n\n####Manuplating date time in excel\n\nwrite.csv(abandoned_match_nodup_all_c ,\"abandoned_match_nodup_all_c.csv\")\n\n\n\n\n\n\n\n\n##########################################\n### SECOND TAKE AT MATCHING DATASETS ####\n##########################################\n\n\n#### CREATING NEW DATASET WITH (CONTACT + INCOMING) and (INCOMING + EMAIL) KEYS\n\n#### Getting Duplicates in both Datasets\n\n#Eamil & Incoming Phone | Contact & Incoming \nmatching_eic = (((abandoned$Incoming_Phone %in% reservation$Incoming_Phone) \n                & (abandoned$Contact_Phone %in% reservation$Contact_Phone) \n                ) |  ((abandoned$Incoming_Phone %in% reservation$Incoming_Phone) \n                     & (abandoned$Email %in% reservation$Email) \n                ) )& \n                (!duplicated(matching_incoming) \n                | !duplicated(matching_contact)\n                | !duplicated(matching_email) )     # To select matching observations in Abandoned DataSet on either email, \n                                      # incoming or Contact phone and removing any duplicates from either.\nmatching_eic\nsum(matching_eic) \nabandoned_match = abandoned[matching_eic,]\nnrow(abandoned_match) #340 obs in Abandoned matched with obs in Reservation Dataset\n\nabandoned_match <- abandoned[matching_eic,]\nabandoned_match\n\n### Getting corresponding matching Reservation Dataset\n\nmatching_eic_r = ((reservation$Incoming_Phone %in% abandoned_match$Incoming_Phone) &\n                 (reservation$Contact_Phone %in% abandoned_match$Contact_Phone))\n                 #Only matching on incoming and contact because email is giving wrong values(matching blanks with blanks)\n                 \n                 \nsum(matching_eic_r) #330\nmatching_eic_r\n\nreservation_match <- reservation[matching_eic_r,]\nreservation_match\n\n(match(reservation_match$Incoming_Phone,abandoned_match$Incoming_Phone)&\n  match(reservation_match$Contact_Phone,abandoned_match$Contact_Phone))\n\n\n\n\n\n\n\n\n##########################################\n##### THIRD TAKE AT MATCHING DATASETS ####\n##########################################\n\n# Created 2 keys in Excel for each data set\n# Key 1: In_Co <- concatinate(incoming,contact)\n# Key 2: In_Em <- concatinate(incoming,email)\n# Removed all blank keys\n\n#loading the 2 datasets with keys\nabandoned = read.csv(\"Abandoned_with_keys.csv\",header = T,stringsAsFactors = F)\nreservation = read.csv(\"Reservation_with_keys.csv\",header = T,stringsAsFactors = F)\n\n\n\n#### Getting Matching in both Datasets\nmatch(abandoned$In_Co,reservation$In_Co,nomatch = 0) | match(abandoned$In_Em,reservation$In_Em,nomatch = 0) #175\nmatch(reservation$In_Co,abandoned$In_Co,nomatch = 0) | match(reservation$In_Em,abandoned$In_Em,nomatch = 0) #186\n\n#In_Co and In_Em \n#abandoned dataset\nmatching_eic = ((abandoned$In_Co %in% reservation$In_Co) | (abandoned$In_Em %in% reservation$In_Em))\nmatching_eic\nsum(matching_eic) \nabandoned_match = abandoned[matching_eic,]\nnrow(abandoned_match) #175 obs in Abandoned matched with obs in Reservation Dataset\n  #removing duplicates\n  sum(!duplicated(abandoned_match)) #still 175 so all good\n  abandoned_match_nodup <- abandoned_match\n\n#reservation dataset\ninco <- match(abandoned_match_nodup$In_Co, reservation$In_Co,nomatch = 0)\ninem <- match(abandoned_match_nodup$In_Em, reservation$In_Em,nomatch = 0)\ninco <- inco[inco != 0]\ninco\ninem <- inem[inem != 0]\ninem\n\nreservation_match <- reservation[c(inco,inem),]\nnrow(reservation_match) #231\n  #removing duplicates\n  reservation_match_nodup <- reservation_match[!duplicated(reservation_match),]\n  nrow(reservation_match_nodup) #171\n\n\n### Getting corresponding matching Reservation Dataset\nmatch(reservation_match_nodup$In_Co, abandoned_match_nodup$In_Co, nomatch = 0)\nmatch(reservation_match_nodup$In_Em, abandoned_match_nodup$In_Em, nomatch = 0)  \nindexinco <- match(abandoned_match_nodup$In_Co, reservation_match_nodup$In_Co, nomatch = 0)\nindexinem <- match(abandoned_match_nodup$In_Em, reservation_match_nodup$In_Em, nomatch = 0)\n\nabandoned_match_nodup[,15] <- indexinco\nabandoned_match_nodup[,16] <- indexinem\n\n### Writing Matched datasets\n\nwrite.csv(x = reservation_match_nodup, file = \"reservation_match_nodup.csv\")\nwrite.csv(x = abandoned_match_nodup, file = \"abandoned_match_nodup.csv\")\n\n\n##### Done in Excel\n\n#NON INTERACTION DATASET\n#Creating Reservation_Index in excel in both datasets to match properly\n#Sorting the datasets in excel according to Res_Index\n#Converting the session variable to datetime in excel\n#Subtracting Reservation session with Abandoned session to get days_in_between\n#Creating days_in_between variable in excel\n#subtituting session variable with days_in_between variable in the abandoned dataset\n#Combining the abandoned dataset with newly created both_matched_v3 dataset\n#removing duplicates with criteria (incoming and contact) first and then (email and incoming). (7325 obs left)\n#replacing days_in_between variable values in abandoned dataset rows with 200. (abandoned dataset rows are above 171)\n#deleting Caller_ID, Last_Name, Street, City, Zipcode variables in the both_matched_aban dataset\n#Adding Customer_ID variable with index as ID from 1 to 7325\n#Creating Variables D_Email (email given: 1), D_State (state given: 1), Outcome (reservation: 1), Test_Variable (test,control)\n#Saving dataset as both_matched_aban_v3\n#Removing Address, Email, Incoming_Phone, Contact_Phone\n#Saving as both_matched_aban_v4\n#deleting First_Name variable and saving dataset as both_matched_aban_v5\n#Final dataset is both_matched_aban_v5 (no interactions)\n\n#INTERACTION DATASET\n#Saved in Interaction Folder\n#both_matched_v3 includes matched abandoned and reservation obs with Date, Time, days_in_between, in_co, in_em\n# Creating Interactions:\n    #Int_T_Email: 0: no email given, time value: email given\n    #Int_T_State: 0: no state given, 1: state given\n#Saved as both_match_V4\n#Combining abandoned with both_match_v4 and saving as both_match_aban_v1\n#Populating Values for Time, Date, Days_in_Between, In_Co, In-Em, Int_T_Email, Int_T_State\n#Saving as both_match_aban_v2\n# Removing Duplicates using In_Co first and then In_Em (7325 obs left)\n#Saving as both_match_aban_v3\n# Converting both interaction variable values to \"only hour\" values\n#Saving as both_match_aban_v4\n#Created Customer_ID, D_Email, D_State, Outcome variables\n#Saving as both_match_aban_v5\n#Deleting Address, email variables and saving as both_match_aban_v6\n#Deleting First_Name and saving as both_match_aban_v7\n#Adding Interactions variables Int_T_State_bin (binary), Int_T_Email_bin (binary), Int_Test_Email (Test*D_Email), Int_Test_State(Test*D_State), Test_Var (binary)\n#Readding First_Names for future analysis (Male/Female) using NLP\n#Saving as both_matching_v8\n\n\n### Reading Final Cleaned Datasets\n\nNon_int_data <- read.csv(\"both_matched_aban_v5.csv\",header = T,stringsAsFactors = F)\nInt_data <- read.csv(\"Datasets for Interactions/both_matched_aban_v7.csv\",header = T,stringsAsFactors = F)\n\n\n#Q2 compute the summary statistics (mean, median, q5, q95, standard deviation) \n#of the Test_variable: a dummy with a value of 1 if tested 0 if control in the ABD database.\n\nTest <- abandoned$Test_Control\nTest[Test==\"test\"] <- 1\nTest[Test==\"control\"] <- 0\n\nmean(as.numeric(Test))\nmedian(as.numeric(Test))\nsd(as.numeric(Test))\nquantile(as.numeric(Test),c(.05,.95))\nhist(as.numeric(Test), main=\"Histogram of Test_Control Variable\",labels = c(\"Control\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Test\"))\n\n\n#Q3: compute the same summary statistics for this Test_variable by blocking on States \n#(meaning considering only the entries with known “State”), wherever this information is available.\n\nTest <- abandoned$Test_Control[abandoned$Address!=\"\"]\nTest[Test==\"test\"] <- 1\nTest[Test==\"control\"] <- 0\nTest <- as.numeric(Test)\nmean(as.numeric(Test))\nmedian(as.numeric(Test))\nsd(as.numeric(Test))\nquantile(as.numeric(Test),c(.05,.95))\nhist(as.numeric(Test), main=\"Histogram of Test_Control Variable (State-only Level)\",labels = c(\"Control\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"Test\"))\n\n#Q7 1: Identification of Customers in the TREATMENT group who bought\nInt_data[(Int_data$Test_Variable==\"test\") & (Int_data$Outcome==1), ]\n\n#(2) Identification of Customers in the TREATMENT group who did not buy\nhead(Int_data[(Int_data$Test_Variable==\"test\") & (Int_data$Outcome!=1), ])\n\n#(3) Identification of Customers in the Control group who bought:\nhead(Int_data[(Int_data$Test_Variable==\"control\") & (Int_data$Outcome==1), ])\n\n#(4) Identification of Customers in the Control group who did not buy\nhead(Int_data[(Int_data$Test_Variable==\"control\") & (Int_data$Outcome!=1), ])\n\n#Q9 Complete the following cross-tabulation:\n\n#Group\\Outcome  Buy\t    No Buy\n#Treatment      Number\tNumber\n#Control\t      Number\tNumber\n\nnrow(Int_data[(Int_data$Test_Variable==\"test\") & (Int_data$Outcome==1), ])\nnrow(Int_data[(Int_data$Test_Variable==\"test\") & (Int_data$Outcome!=1), ])\nnrow(Int_data[(Int_data$Test_Variable==\"control\") & (Int_data$Outcome==1), ])\nnrow(Int_data[(Int_data$Test_Variable==\"control\") & (Int_data$Outcome!=1), ])\n\n#Group\\Outcome  Buy\t    No Buy\n#Treatment      139   \t3541\n#Control\t      30    \t3614\n\nlibrary(ggplot2)                           \n# Setting up the vectors                           \nOutcome <- c(\"Buy\",\"No Buy\")\nGroup <- c(\"Control\",\"Trearment\")\n# Creating data frame\ndf <- expand.grid(Outcome, Group)\ndf$value <- c(30,3614,139,3541)    \n#Plotting Data\ng <- ggplot(df, aes(Var1, Var2)) + geom_point(aes(size = value), colour = \"green\") + theme_bw() + xlab(\"Outcome\") + ylab(\"Group\")\ng + scale_size_continuous(range=c(10,30)) + geom_text(aes(label = value))\n\n\n#Q10 Repeat Q9 for 5 randomly picked states. Report 5 different tables by specifying the states you “randomly picked”.\nQ10 <- read.csv(\"Datasets for Interactions/both_matched_aban_v5.csv\",header = TRUE,stringsAsFactors = FALSE)\n\n#LA\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome==1) & (Q10$Address==\"LA\"), ])\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome!=1) & (Q10$Address==\"LA\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome==1) & (Q10$Address==\"LA\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome!=1) & (Q10$Address==\"LA\"), ])\n\n#ND\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome==1) & (Q10$Address==\"ND\"), ])\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome!=1) & (Q10$Address==\"ND\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome==1) & (Q10$Address==\"ND\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome!=1) & (Q10$Address==\"ND\"), ])\n\n#MO\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome==1) & (Q10$Address==\"MO\"), ])\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome!=1) & (Q10$Address==\"MO\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome==1) & (Q10$Address==\"MO\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome!=1) & (Q10$Address==\"MO\"), ])\n\n#WY\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome==1) & (Q10$Address==\"WY\"), ])\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome!=1) & (Q10$Address==\"WY\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome==1) & (Q10$Address==\"WY\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome!=1) & (Q10$Address==\"WY\"), ])\n\n#OR\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome==1) & (Q10$Address==\"OR\"), ])\nnrow(Q10[(Q10$Test_Variable==\"test\") & (Q10$Outcome!=1) & (Q10$Address==\"OR\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome==1) & (Q10$Address==\"OR\"), ])\nnrow(Q10[(Q10$Test_Variable==\"control\") & (Q10$Outcome!=1) & (Q10$Address==\"OR\"), ])\n\n\n#Q11: Run a Linear regression model for Outcome = alpha + beta * Test_Variable + error\n\nfit <- lm(Outcome~Test_Variable, data=Int_data)\nfit\nsummary(fit)\nplot(fit)\n\n\n#Q14: Now add to the regression model the dummies for State and Emails. Also consider \n#including interactions with the treatment. Report the outcome and comment on the results. \n#(You can compare with Q10)\n\nInt_data_v2 <- read.csv(\"Datasets for Interactions/both_matched_aban_v8.csv\",header = TRUE,stringsAsFactors = FALSE)\n",
    "created" : 1442766900176.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1269216841",
    "id" : "59E98DE7",
    "lastKnownWriteTime" : 1443359104,
    "path" : "~/Studies/Courses/USF/Statistical Data Mining/MightyHive Project/MightyHive-Project/MightyHive Project.R",
    "project_path" : "MightyHive Project.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "type" : "r_source"
}